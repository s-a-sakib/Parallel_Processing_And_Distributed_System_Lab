{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWy4ZqRLAVWl",
        "outputId": "f7860381-392f-4036-9704-acf8a373f6f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Feb  7 16:48:49 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8             12W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "\n",
        "#sudo apt update\n",
        "#sudo apt install openmpi-bin openmpi-common libopenmpi-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5QdHwV2A9Ap",
        "outputId": "a458c8f4-c948-4def-a4d0-62ee4f95b084"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting multiplication.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile multiplication.cu\n",
        "\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <time.h>\n",
        "using namespace std;\n",
        "\n",
        "__global__ void multiplication(int *a, int *b, int *c, int n){\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if(row < n && col < n){\n",
        "        int sum = 0;\n",
        "        for(int j = 0; j < n; j++){\n",
        "            sum += a[row * n + j] * b[j * n + col];\n",
        "        }\n",
        "        c[row * n + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "  int n = 40;\n",
        "  size_t bytes = n * n * sizeof(int);\n",
        "  int a[n][n], b[n][n], c[n][n];\n",
        "\n",
        "  srand(time(0));\n",
        "  for(int i = 0; i < n; i++){\n",
        "    for(int j = 0; j < n; j++){\n",
        "      a[i][j] = 1;\n",
        "      b[i][j] = 1;\n",
        "    }\n",
        "  }\n",
        "\n",
        "  int *d_a, *d_b, *d_c;\n",
        "  cudaMalloc(&d_a, bytes);\n",
        "  cudaMalloc(&d_b, bytes);\n",
        "  cudaMalloc(&d_c, bytes);\n",
        "\n",
        "  cudaMemcpy(d_a, a, bytes, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_b, b, bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "  dim3 threads(4,16);\n",
        "  dim3 blocks((n + threads.x - 1)/threads.x,(n + threads.y - 1)/threads.y);\n",
        "\n",
        "  // Event for timing\n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "\n",
        "  cudaEventRecord(start, 0);\n",
        "  multiplication<<<blocks, threads>>>(d_a, d_b, d_c, n);\n",
        "  cudaEventRecord(stop, 0);\n",
        "\n",
        "  cudaEventSynchronize(stop);\n",
        "\n",
        "  float milliseconds = 0;\n",
        "  cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "  cudaMemcpy(c, d_c, bytes, cudaMemcpyDeviceToHost);\n",
        "  cudaFree(d_a);\n",
        "  cudaFree(d_b);\n",
        "  cudaFree(d_c);\n",
        "\n",
        "  cudaEventDestroy(start);\n",
        "  cudaEventDestroy(stop);\n",
        "\n",
        "  for(int i = 0; i < n; i++){\n",
        "    for(int j = 0; j < n; j++){\n",
        "      cout << c[i][j] << \"  \";\n",
        "    }\n",
        "    cout << endl;\n",
        "  }\n",
        "  cout << \"Kernel execution time: \" << milliseconds << \" ms\" << endl;\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD5JQ6ndFY3r",
        "outputId": "d24483cf-41a6-449a-bfee-75d6d2c31ac5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  40  \n",
            "Kernel execution time: 0.094912 ms\n"
          ]
        }
      ],
      "source": [
        "!nvcc -gencode arch=compute_75,code=sm_75 multiplication.cu -o matrix2D\n",
        "!./matrix2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQLQL8dNHFNk",
        "outputId": "b311f65a-e94a-4bf2-c1f0-7691e9a6c515"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting phonebook_search.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile phonebook_search.cu\n",
        "#include <bits/stdc++.h>\n",
        "#include <cuda_runtime.h>\n",
        "using namespace std;\n",
        "\n",
        "__device__ int search_substring(const char *text, int text_length,\n",
        "                                const char *pattern, int pattern_length){\n",
        "    if(pattern_length == 0) return 1;\n",
        "    if(text_length < pattern_length) return 0;\n",
        "\n",
        "    for(int i = 0; i <= text_length - pattern_length; i++){\n",
        "        int j = 0;\n",
        "        while(j < pattern_length && text[i + j] == pattern[j]) j++;\n",
        "        if(j == pattern_length) return 1;\n",
        "    }\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "__global__ void search_phonebook(const char *phonebook, int lineWidth, int count,\n",
        "                                 const char *pattern, int patternLen,\n",
        "                                 int *result){\n",
        "    int id = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if(id >= count) return;\n",
        "\n",
        "    const char* line = phonebook + id * lineWidth;\n",
        "\n",
        "    int len = 0;\n",
        "    while(len < lineWidth && line[len] != '\\0') len++;\n",
        "\n",
        "    result[id] = search_substring(line, len, pattern, patternLen);\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    string filename = \"phonebook1.txt\";\n",
        "    ifstream file(filename);\n",
        "    if(!file){\n",
        "        cerr << \"File not found\\n\";\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    vector<string> lines;\n",
        "    string line;\n",
        "    while(getline(file, line)){\n",
        "        lines.push_back(line);\n",
        "    }\n",
        "    file.close();\n",
        "\n",
        "    int count = (int)lines.size();\n",
        "    if(count == 0){\n",
        "        cout << \"No lines\\n\";\n",
        "        return 0;\n",
        "    }\n",
        "\n",
        "    char name[100];\n",
        "    cout << \"Enter the name to search: \";\n",
        "    cin.getline(name, 100);\n",
        "    int patternLen = (int)strlen(name);\n",
        "\n",
        "    const int LINE_WIDTH = 100;\n",
        "\n",
        "    vector<char> phonebook(count * LINE_WIDTH, 0);\n",
        "    for(int i = 0; i < count; i++){\n",
        "        strncpy(&phonebook[i * LINE_WIDTH], lines[i].c_str(), LINE_WIDTH - 1);\n",
        "    }\n",
        "\n",
        "    char *d_phonebook, *d_pattern;\n",
        "    int *d_result;\n",
        "\n",
        "    cudaMalloc(&d_phonebook, phonebook.size());\n",
        "    cudaMalloc(&d_pattern, patternLen + 1);\n",
        "    cudaMalloc(&d_result, count * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_phonebook, phonebook.data(), phonebook.size(), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_pattern, name, patternLen + 1, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int threads = 256;\n",
        "    int blocks = (count + threads - 1) / threads;\n",
        "\n",
        "    search_phonebook<<<blocks, threads>>>(d_phonebook, LINE_WIDTH, count,\n",
        "                                          d_pattern, patternLen, d_result);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    vector<int> result(count);\n",
        "    cudaMemcpy(result.data(), d_result, count * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    for(int i = 0; i < count; i++){\n",
        "        if(result[i]){\n",
        "            cout << lines[i] << \"\\n\";\n",
        "        }\n",
        "    }\n",
        "\n",
        "    cudaFree(d_phonebook);\n",
        "    cudaFree(d_pattern);\n",
        "    cudaFree(d_result);\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr9WOp5HKhYX",
        "outputId": "cbb427d9-8367-44cb-a9fe-5feefa0dac42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the name to search: DOL\n",
            "\"MARIYA AZAD DOLA\",\"016 14 266\"\n",
            "\"DOLA RANI DEY\",\"016 64 310\"\n",
            "\"DOLON RANI DAS\",\"014 38 502\"\n",
            "\"DOLA BEGUM\",\"016 45 463\"\n",
            "\"NIPA RANI MONDOL\",\"012 68 453\"\n"
          ]
        }
      ],
      "source": [
        "!nvcc -O2 -gencode arch=compute_75,code=sm_75 phonebook_search.cu -o phonebook_search\n",
        "!./phonebook_search\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
